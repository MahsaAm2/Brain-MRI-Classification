{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision\n",
    "#import fastai\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import random\n",
    "import sklearn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "#import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from skimage import morphology\n",
    "from PIL import ImageOps\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.46.670589.11.10042.5.0.6048.20240307143704...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.46.670589.11.10042.5.0.6048.20240307143746...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3.46.670589.11.10042.5.0.6048.20240307143846...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.46.670589.11.10042.5.0.4776.20240217030800...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.46.670589.11.10042.5.0.4776.20240217030846...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SeriesInstanceUID  prediction\n",
       "0  1.3.46.670589.11.10042.5.0.6048.20240307143704...           0\n",
       "1  1.3.46.670589.11.10042.5.0.6048.20240307143746...           0\n",
       "2  1.3.46.670589.11.10042.5.0.6048.20240307143846...           0\n",
       "3  1.3.46.670589.11.10042.5.0.4776.20240217030800...           0\n",
       "4  1.3.46.670589.11.10042.5.0.4776.20240217030846...           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = 'G:/MRI-challange/train.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('G:/MRI-challange/separated_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders separated successfully!\n"
     ]
    }
   ],
   "source": [
    "separated_data_folder = 'G:/MRI-challange/separated_data'\n",
    "data_folder = 'G:/MRI-challange/data'\n",
    "\n",
    "normal_folder = os.path.join(separated_data_folder, 'normal')\n",
    "abnormal_folder = os.path.join(separated_data_folder, 'abnormal')\n",
    "\n",
    "os.makedirs(normal_folder, exist_ok=True)\n",
    "os.makedirs(abnormal_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the CSV file and move folders\n",
    "for index, row in df.iterrows():\n",
    "    series_uid = row['SeriesInstanceUID']\n",
    "    prediction = row['prediction']\n",
    "    \n",
    "    # Determine the source and destination paths\n",
    "    src_folder = os.path.join(data_folder, series_uid)\n",
    "    if prediction == 0:\n",
    "        dst_folder = os.path.join(normal_folder, series_uid)\n",
    "    else:\n",
    "        dst_folder = os.path.join(abnormal_folder, series_uid)\n",
    "    \n",
    "    # Move the folder\n",
    "    if os.path.exists(src_folder):\n",
    "        shutil.copytree(src_folder, dst_folder)\n",
    "    else:\n",
    "        print(f\"Folder {src_folder} does not exist\")\n",
    "\n",
    "print(\"Folders separated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('G:/MRI-challange/splited_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train, val, and test sets successfully!\n"
     ]
    }
   ],
   "source": [
    "# Paths to the normal and abnormal folders\n",
    "\n",
    "base_folder = 'G:/MRI-challange/splited_dataset'\n",
    "\n",
    "# Split ratios\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Create directories for train, val, and test sets\n",
    "train_folder = os.path.join(base_folder, 'train')\n",
    "val_folder = os.path.join(base_folder, 'val')\n",
    "test_folder = os.path.join(base_folder, 'test')\n",
    "\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(train_folder, 'normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_folder, 'abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_folder, 'normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_folder, 'abnormal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_folder, 'normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_folder, 'abnormal'), exist_ok=True)\n",
    "\n",
    "# Function to split and move folders\n",
    "def split_and_move_folders(src_folder, dst_base_folder):\n",
    "    folders = [f for f in os.listdir(src_folder) if os.path.isdir(os.path.join(src_folder, f))]\n",
    "    random.shuffle(folders)\n",
    "    \n",
    "    train_count = int(len(folders) * train_ratio)\n",
    "    val_count = int(len(folders) * val_ratio)\n",
    "    test_count = len(folders) - train_count - val_count\n",
    "    \n",
    "    splits = {\n",
    "        'train': folders[:train_count],\n",
    "        'val': folders[train_count:train_count + val_count],\n",
    "        'test': folders[train_count + val_count:]\n",
    "    }\n",
    "    \n",
    "    for split, split_folders in splits.items():\n",
    "        for folder in split_folders:\n",
    "            src_path = os.path.join(src_folder, folder)\n",
    "            dst_path = os.path.join(dst_base_folder, split, os.path.basename(src_folder), folder)\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "# Split and move normal and abnormal folders\n",
    "split_and_move_folders(normal_folder, base_folder)\n",
    "split_and_move_folders(abnormal_folder, base_folder)\n",
    "\n",
    "print(\"Data split into train, val, and test sets successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_dicom(src_folder, dst_folder):\n",
    "    for root, _, files in os.walk(src_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                dicom_path = os.path.join(root, file)\n",
    "                dicom_data = pydicom.dcmread(dicom_path)\n",
    "            if 'T2W_TSE'  in dicom_data.ProtocolName:\n",
    "\n",
    "                # Extract metadata\n",
    "                slice_orientation = dicom_data[(0x2001, 0x100b)].value\n",
    "                if (slice_orientation != 'SAGITTAL') and (slice_orientation != 'CORONAL'):\n",
    "                    pixel_array = dicom_data.pixel_array\n",
    "                    protocol_name = dicom_data.ProtocolName.replace(\" \", \"_\")  # Remove spaces in description\n",
    "                    instance_number = dicom_data.InstanceNumber\n",
    "\n",
    "                    # Extract Image Orientation (Patient) tag to determine left-right orientation\n",
    "                    image_orientation = dicom_data[0x0020, 0x0037].value\n",
    "\n",
    "                    # Check if the first element of image_orientation is negative\n",
    "                    # This would indicate a left-to-right orientation, requiring a flip\n",
    "                    if image_orientation[0] < 0:\n",
    "                        # Flip the image horizontally to make it right-to-left\n",
    "                        pixel_array = np.fliplr(pixel_array)\n",
    "\n",
    "                    # Get the original folder name (parent of current root)\n",
    "                    original_folder_name = os.path.basename(root)\n",
    "\n",
    "                    # Create a new folder for the subject using original folder name + PatientID\n",
    "                    subject_folder_name = f\"{original_folder_name}\"\n",
    "                    subject_folder = os.path.join(dst_folder, subject_folder_name)\n",
    "                    os.makedirs(subject_folder, exist_ok=True)\n",
    "\n",
    "                    # Construct the save path with instance number in the filename\n",
    "                    save_path = os.path.join(subject_folder, f\"{os.path.splitext(file)[0]}_{protocol_name}_Instance{instance_number}.npy\")\n",
    "\n",
    "                    # Save the numpy array\n",
    "                    np.save(save_path, pixel_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICOM files processed and saved as NumPy arrays with SeriesDescription in filenames.\n"
     ]
    }
   ],
   "source": [
    "base_folder = 'G:/MRI-challange/splited_dataset'\n",
    "output_folder = 'G:/MRI-challange/final_data_T2'\n",
    "\n",
    "# Create output directories for train, val, and test sets\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    for category in ['normal', 'abnormal']:\n",
    "        os.makedirs(os.path.join(output_folder, subset, category), exist_ok=True)\n",
    "\n",
    "# Process and save DICOM files in train, val, and test sets\n",
    "for subset in ['train', 'val', 'test']:\n",
    "    for category in ['normal', 'abnormal']:\n",
    "        src_folder = os.path.join(base_folder, subset, category)\n",
    "        dst_folder = os.path.join(output_folder, subset, category)\n",
    "        process_and_save_dicom(src_folder, dst_folder)\n",
    "\n",
    "print(\"DICOM files processed and saved as NumPy arrays with SeriesDescription in filenames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instance_number(filename):\n",
    "    \"\"\"Extract the instance number from the filename.\"\"\"\n",
    "    # Assuming the instance number is always preceded by 'Instance'\n",
    "    base_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    instance_str = base_name.split('_')[-1]  # Get the last part after splitting by '_'\n",
    "    \n",
    "    # Remove any non-digit characters from the instance part to extract the number\n",
    "    instance_number = ''.join(filter(str.isdigit, instance_str))\n",
    "    \n",
    "    return int(instance_number)\n",
    "\n",
    "def show_all_slices_of_random_subject(output_folder):\n",
    "    # List all subject folders in the output directory\n",
    "    subject_folders = [f.path for f in os.scandir(output_folder) if f.is_dir()]\n",
    "    \n",
    "    if not subject_folders:\n",
    "        print(\"No subjects found in the output folder.\")\n",
    "        return\n",
    "    \n",
    "    # Select a random subject folder\n",
    "    random_subject_folder = random.choice(subject_folders)\n",
    "    print(f\"Displaying all slices for subject: {os.path.basename(random_subject_folder)}\")\n",
    "    \n",
    "    # Get all .npy files in the subject's folder\n",
    "    npy_files = [os.path.join(random_subject_folder, f) for f in os.listdir(random_subject_folder) if f.endswith(\".npy\")]\n",
    "    \n",
    "    if not npy_files:\n",
    "        print(\"No .npy files found for the selected subject.\")\n",
    "        return\n",
    "    \n",
    "    # Sort files based on extracted instance numbers\n",
    "    npy_files = sorted(npy_files, key=extract_instance_number)\n",
    "\n",
    "    # Number of slices\n",
    "    num_slices = len(npy_files)\n",
    "    \n",
    "    # Determine grid size (rows and columns) for displaying the slices\n",
    "    num_columns = 5  # Display 5 images per row\n",
    "    num_rows = (num_slices + num_columns - 1) // num_columns  # Calculate the number of rows needed\n",
    "    \n",
    "    # Create a figure with the calculated grid size\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, num_rows * 3))\n",
    "    axes = axes.flatten()  # Flatten the axes array\n",
    "    \n",
    "    # Display each slice in the grid\n",
    "    for i, file_path in enumerate(npy_files):\n",
    "        # Load the image data from the .npy file\n",
    "        image_data = np.load(file_path)\n",
    "        \n",
    "        # Extract the instance number using the defined function\n",
    "        instance_number = extract_instance_number(file_path)\n",
    "        \n",
    "        # Display the image and set the title as the instance number\n",
    "        axes[i].imshow(image_data, cmap='gray')\n",
    "        axes[i].set_title(f\"Instance {instance_number}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_background(image, target_size=(256, 256)):\n",
    "        \"\"\"\n",
    "        Crops the black background from the image using a tighter thresholding and bounding box method.\n",
    "        Assumes that the image has dimensions (height, width, channels).\n",
    "        \"\"\"\n",
    "        # If image has multiple channels, use only the first channel for thresholding\n",
    "        if len(image.shape) == 3:  # (height, width, channels)\n",
    "            image_2d = image[:, :, 0]  # Use the first channel for cropping\n",
    "        else:\n",
    "            image_2d = image\n",
    "\n",
    "        # Adjusted thresholding: using a higher percentile for a tighter crop\n",
    "        binary_image = image_2d > np.percentile(image_2d, 60)  # Increase percentile to 15 or higher if needed\n",
    "\n",
    "        # Remove small connected components (noise) - optional\n",
    "        binary_image = morphology.remove_small_objects(binary_image, min_size=100)\n",
    "\n",
    "        # Visualize the binary image\n",
    "        plt.imshow(binary_image, cmap='gray')\n",
    "        plt.title(\"Tighter Binary Image\")\n",
    "        plt.show()\n",
    "\n",
    "        # Find the bounding box\n",
    "        coords = np.column_stack(np.where(binary_image))\n",
    "        if coords.size == 0:\n",
    "            # Handle the case where the image is completely black\n",
    "            return image  # Return the original image if there's no valid crop\n",
    "\n",
    "        min_row, min_col = coords.min(axis=0)\n",
    "        max_row, max_col = coords.max(axis=0)\n",
    "\n",
    "        # Apply a tighter crop using the bounding box\n",
    "        cropped_image = image[min_row:max_row+1, min_col:max_col+1]\n",
    "\n",
    "        # Convert cropped image to PIL Image and ensure it is in 'L' mode (grayscale)\n",
    "        cropped_image = Image.fromarray(cropped_image.squeeze())\n",
    "        cropped_image = ImageOps.grayscale(cropped_image)\n",
    "        \n",
    "        cropped_image = cropped_image.resize(target_size, Image.LANCZOS)\n",
    "        cropped_image = np.array(cropped_image)\n",
    "\n",
    "        # Ensure the resized image has the correct shape (target_size, target_size, channels)\n",
    "        if len(cropped_image.shape) == 2:  # Ensure it's still 2D\n",
    "            cropped_image = np.expand_dims(cropped_image, axis=-1)\n",
    "\n",
    "        # Visualize the final tightly cropped and resized image\n",
    "        plt.imshow(cropped_image.squeeze(), cmap='gray')\n",
    "        plt.title(f\"Final Cropped and Resized Image: {cropped_image.shape}\")\n",
    "        plt.show()\n",
    "\n",
    "        return cropped_image\n",
    "\n",
    "\n",
    "def process_subject_slices(subject_folder):\n",
    "    \"\"\"Process the slices of a subject, resize them, split into hemispheres, and return the array.\"\"\"\n",
    "    \n",
    "    # Get all .npy files in the subject's folder\n",
    "    npy_files = [os.path.join(subject_folder, f) for f in os.listdir(subject_folder) if f.endswith(\".npy\")]\n",
    "    \n",
    "    if not npy_files:\n",
    "        print(\"No .npy files found in the selected subject folder.\")\n",
    "        return None\n",
    "    \n",
    "    # Sort files based on extracted instance numbers\n",
    "    npy_files = sorted(npy_files, key=extract_instance_number)\n",
    "    \n",
    "    # Limit to the first 16 slices, or pad with zeros if there are fewer\n",
    "    num_slices = 16\n",
    "    processed_slices = []\n",
    "    \n",
    "    for i in range(num_slices):\n",
    "        if i < len(npy_files):\n",
    "            image_data = np.load(npy_files[i])\n",
    "        else:\n",
    "            # Create a zero array if there are not enough slices\n",
    "            image_data = np.zeros((288, 288))  # Assuming original slices are 288x288\n",
    "            \n",
    "            \n",
    "        # CROPPING ADDED HERE\n",
    "        image_data = crop_background(image_data)\n",
    "        \n",
    "        # Resize to 256x256\n",
    "        resized_slice = cv2.resize(image_data, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        processed_slices.append([resized_slice])\n",
    "    \n",
    "    # Convert to numpy array with shape (16, 2, 256, 128)\n",
    "    processed_slices = np.array(processed_slices)\n",
    "    \n",
    "    return processed_slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new histogram func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histograms_for_subject(subject_folder, num_bins=255):\n",
    "    # Get all .npy files in the subject's folder\n",
    "    npy_files = [os.path.join(subject_folder, f) for f in os.listdir(subject_folder) if f.endswith(\".npy\")]\n",
    "    \n",
    "    if not npy_files:\n",
    "        print(f\"No .npy files found for the subject folder: {subject_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort files to maintain order (assuming filenames include instance numbers)\n",
    "    npy_files.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1].replace(\"Instance\", \"\")))\n",
    "\n",
    "    all_histograms = []\n",
    "\n",
    "    # We only want slices 5, 6, 7, and 8 (index 4 to 7)\n",
    "    for i, file_path in enumerate(npy_files[4:8]):\n",
    "        # Load the image data from the .npy file\n",
    "        image_data = np.load(file_path)\n",
    "        \n",
    "        # Resize the image to 256x256\n",
    "        resized_image = cv2.resize(image_data, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Exclude zeros and compute histograms\n",
    "        resized_image_nonzero = resized_image[resized_image > 0]\n",
    "\n",
    "        resized_image_hist, _ = np.histogram(resized_image[resized_image > 0], bins=num_bins, range=(0, 255))\n",
    "        \n",
    "        # If no non-zero pixels are found, skip this slice\n",
    "        if resized_image_hist.sum() == 0:\n",
    "            print(f\"Skipping slice with no non-zero pixels in file: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Normalize histogram to ensure equal contribution of each slice\n",
    "        if resized_image_hist.sum() > 0:\n",
    "            resized_image_hist = resized_image_hist / np.sum(resized_image_hist)\n",
    "        \n",
    "        all_histograms.append(resized_image_hist)\n",
    "    \n",
    "    # If no valid histograms were found, return None\n",
    "    if not all_histograms:\n",
    "        print(f\"No valid histograms found for the subject folder: {subject_folder}\")\n",
    "        return None\n",
    "    \n",
    "    # Flatten the list of histograms into a single feature vector\n",
    "    subject_histogram_vector = np.concatenate(all_histograms)\n",
    "    \n",
    "    return subject_histogram_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainHistogramDataset(Dataset):\n",
    "    def __init__(self, base_folder, num_bins=255):\n",
    "        self.num_bins = num_bins\n",
    "        \n",
    "        # List all subject folders in both 'normal' and 'abnormal' directories\n",
    "        normal_folder = os.path.join(base_folder, 'normal')\n",
    "        abnormal_folder = os.path.join(base_folder, 'abnormal')\n",
    "        \n",
    "        self.subject_folders = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Add normal subjects\n",
    "        normal_subject_folders = [os.path.join(normal_folder, f) for f in os.listdir(normal_folder) if os.path.isdir(os.path.join(normal_folder, f))]\n",
    "        self.subject_folders.extend(normal_subject_folders)\n",
    "        self.labels.extend([0] * len(normal_subject_folders))  # Label 0 for normal\n",
    "     \n",
    "        \n",
    "        # Add abnormal subjects\n",
    "        abnormal_subject_folders = [os.path.join(abnormal_folder, f) for f in os.listdir(abnormal_folder) if os.path.isdir(os.path.join(abnormal_folder, f))]\n",
    "        self.subject_folders.extend(abnormal_subject_folders)\n",
    "        self.labels.extend([1] * len(abnormal_subject_folders))  # Label 1 for abnormal\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subject_folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_folder = self.subject_folders[idx]\n",
    "        histogram_vector = compute_histograms_for_subject(subject_folder, self.num_bins)\n",
    "        \n",
    "        # Handle cases where histogram_vector is None\n",
    "        if histogram_vector is None:\n",
    "            histogram_vector = np.zeros(16 * self.num_bins)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(histogram_vector, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "            \n",
    "    def ret_label(self):\n",
    "        return  self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your data folders\n",
    "train_folder = 'G:/MRI-challange/final_data_T1/train'\n",
    "val_folder = 'G:/MRI-challange/final_data_T1/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = BrainHistogramDataset(train_folder)\n",
    "val_dataset = BrainHistogramDataset(val_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_weights(train_dataset):\n",
    "    # Extract labels from the dataset\n",
    "    labels = [label for _, label in train_dataset]\n",
    "    \n",
    "    # Calculate the number of samples per class\n",
    "    class_sample_counts = np.bincount(labels)\n",
    "    \n",
    "    # Compute class weights as the inverse of the class sample counts\n",
    "    class_weights = 1.0 / (class_sample_counts + 1e-9)  # Adding a small value to avoid division by zero\n",
    "    \n",
    "    # Normalize class weights (optional)\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "    print(class_weights)\n",
    "    \n",
    "    # Create sample weights based on class weights\n",
    "    sample_weights = np.array([class_weights[label] for label in labels])\n",
    "    \n",
    "    # Scale the weights if they are too small\n",
    "    sample_weights *= len(sample_weights)  # Scale by the number of samples\n",
    "    \n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23970944 1.76029056]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "sample_weights = compute_sample_weights(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'G:/MRI-challange/final_data_T1/test'\n",
    "test_dataset = BrainHistogramDataset(test_folder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.ret_label()\n",
    "val_labels = val_dataset.ret_label()\n",
    "test_labels = test_dataset.ret_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step to gather all histogram vectors first\n",
    "def compute_all_histograms(dataset):\n",
    "    all_histograms = []\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        subject_folder = dataset.subject_folders[idx]\n",
    "        histogram_vector = compute_histograms_for_subject(subject_folder)\n",
    "        \n",
    "        if histogram_vector is not None:\n",
    "            all_histograms.append(histogram_vector)\n",
    "    \n",
    "    return np.array(all_histograms)\n",
    "\n",
    "# Step to fit and apply PCA after gathering all histograms\n",
    "def apply_pca_to_histograms(all_histograms, target_dim=20):\n",
    "    pca = PCA(n_components=target_dim)\n",
    "    reduced_histograms = pca.fit_transform(all_histograms)\n",
    "    return reduced_histograms, pca\n",
    "\n",
    "# Use these functions after loading your dataset\n",
    "all_histograms = compute_all_histograms(train_dataset)\n",
    "reduced_histograms, r_pca = apply_pca_to_histograms(all_histograms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def apply_pca_to_test_histograms(test_dataset, pca):\n",
    "    all_histograms_test = compute_all_histograms(test_dataset)\n",
    "    reduced_histograms_test = pca.transform(all_histograms_test)\n",
    "    return reduced_histograms_test\n",
    "\n",
    "reduced_histograms_val = apply_pca_to_test_histograms(val_dataset, r_pca)\n",
    "print(\"done\")\n",
    "reduced_histograms_test = apply_pca_to_test_histograms(test_dataset, r_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(826, 20)\n",
      "(102, 20)\n",
      "(107, 20)\n"
     ]
    }
   ],
   "source": [
    "reduced_histograms_train = reduced_histograms\n",
    "print(reduced_histograms_train.shape)\n",
    "print(reduced_histograms_val.shape)\n",
    "print(reduced_histograms_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducedHistogramDataset(Dataset):\n",
    "    def __init__(self, histograms, labels):\n",
    "        self.histograms = histograms\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.histograms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        histogram = self.histograms[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(histogram, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = ReducedHistogramDataset(reduced_histograms_train, train_labels)\n",
    "val_dataset = ReducedHistogramDataset(reduced_histograms_val, val_labels)\n",
    "test_dataset = ReducedHistogramDataset(reduced_histograms_test, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA model saved as pca_model_flair.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_pca_model(pca, filename='pca_model_flair.pkl'):\n",
    "    joblib.dump(pca, filename)\n",
    "    print(f\"PCA model saved as {filename}\")\n",
    "\n",
    "# Save the PCA model\n",
    "save_pca_model(r_pca, 'pca_model_flair.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def train_svm(train_loader, val_loader,test_loader, kernel='rbf', C=1.0):\n",
    "    # Prepare the training data from the train_loader\n",
    "    X_train, y_train = [], []\n",
    "    for inputs, labels in train_loader:\n",
    "        X_train.extend(inputs.cpu().numpy())\n",
    "        y_train.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Prepare the validation data from the val_loader\n",
    "    X_val, y_val = [], []\n",
    "    for inputs, labels in val_loader:\n",
    "        X_val.extend(inputs.cpu().numpy())\n",
    "        y_val.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert both training and validation data to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    # Combine training and validation data\n",
    "    X_combined = np.concatenate([X_train, X_val])\n",
    "    y_combined = np.concatenate([y_train, y_val])\n",
    "    \n",
    "\n",
    "    # Initialize and train the SVM model on the combined data\n",
    "    svm_model = SVC(kernel=kernel, C=C, probability=True)  # Use probability=True to enable ROC/AUC computation\n",
    "    svm_model.fit(X_combined, y_combined)\n",
    "\n",
    "    # Validation\n",
    "    X_test, y_test = [], []\n",
    "    for inputs, labels in test_loader:\n",
    "        X_test.extend(inputs.cpu().numpy())\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # Standardize validation data using the same scaler\n",
    "   # X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Make predictions and compute probabilities\n",
    "    preds = svm_model.predict(X_test)\n",
    "    probs = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute performance metrics\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    auc_score = roc_auc_score(y_test, probs)\n",
    "    auc_pr = average_precision_score(y_test, probs)\n",
    "\n",
    "    print(f'Validation - Precision: {precision:.4f}, Recall: {recall:.4f}, AUC: {auc_score:.4f}, AUC-PR: {auc_pr:.4f}')\n",
    "    return svm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_MODEL = train_svm(train_loader, val_loader,test_loader, kernel='poly', C=0.9)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5372944,
     "sourceId": 8931416,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
